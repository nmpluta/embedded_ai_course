{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "635f5b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/pynq-venv/lib/python3.8/site-packages/pynq/pl_server/xrt_device.py:59: UserWarning: xbutil failed to run - unable to determine XRT version\n",
      "  warnings.warn(\"xbutil failed to run - unable to determine XRT version\")\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import platform\n",
    "import tqdm\n",
    "from typing import Tuple, List, Union, Any\n",
    "import pynq_dpu\n",
    "import pynq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edb8d747",
   "metadata": {},
   "source": [
    "### This is the final part where we will test our model after quantisation on the target platform."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c47e3c51",
   "metadata": {},
   "source": [
    "We define at the beginning the `TimeMeasurement` class. This is exactly the same class that we used in the previous two steps. It will allow us to check the processing time of the data.\n",
    "\n",
    "In addition, we create the `EvalLoader` class. It will let us read the data stored in `.npz` format that we prepared in the previous section. By default, we set the size of the batch to 1, and the file name is `eval_MNIST.npz`. Only adjust the name if it does not match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d15c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalLoader:\n",
    "    def __init__(self, \n",
    "                 batch_size: int = 1, \n",
    "                 npz_path: str = 'eval_MNIST.npz') -> None:\n",
    "        data = np.load(npz_path)\n",
    "        self.data = data['data'].astype(np.float32)\n",
    "        self.targets = data['targets']\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if i >= len(self):\n",
    "            raise StopIteration\n",
    "\n",
    "        beg = min(i * self.batch_size, self.data.shape[0])\n",
    "        end = min(beg + self.batch_size, self.data.shape[0])\n",
    "\n",
    "        return self.data[beg:end, ...], self.targets[beg:end]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] // self.batch_size\n",
    "\n",
    "\n",
    "class TimeMeasurement:\n",
    "    def __init__(self, context_name: str, frames: int) -> None:\n",
    "        self.context_name: str = context_name\n",
    "        self.frames: int = frames\n",
    "        self.begin: float = None\n",
    "        self.end: float = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.begin = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.end = time.time()\n",
    "\n",
    "    @property\n",
    "    def time(self) -> float:\n",
    "        if self.begin is None or self.end is None:\n",
    "            raise RuntimeError()\n",
    "        return int(self.end - self.begin)\n",
    "\n",
    "    @property\n",
    "    def fps(self):\n",
    "        return self.frames / self.time\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        t = self.time\n",
    "        h = t // 60\n",
    "        min = (t - h*60) // 60\n",
    "        s = int(t - h*60 - min*60)\n",
    "        ms = int((t - np.floor(t))*1000)\n",
    "\n",
    "        return f\"Execution time: {h}:{min}:{s}:{ms}, processed {self.frames} frames, throughput: {self.fps} fps.\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        t = self.time\n",
    "        h = t // 60\n",
    "        min = (t - h*60) // 60\n",
    "        s = np.floor(t - h*60 - min*60)\n",
    "        ms = np.floor((t - np.floor(t))*1000)\n",
    "\n",
    "        return f'TimeMeasurement(context=\"{self.context_name}\",\"{h}:{min}:{s}:{ms}\", frames={self.frames}, throughput={self.fps})'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6363babd",
   "metadata": {},
   "source": [
    "We define the `Accuracy` metric. This is the same as in the previous sections, but you can define it yourself. \n",
    "\n",
    "From the `y_pred` values, determine the maximum values with the `np.argmax` function. Do this relative to `axis=1`. Then compare the resulting vector with `y_ref`. Enter the result of the comparison into the `cmp` variable. Finally, determine the `score` value, which is equal to the summed value of the `cmp` vector (.sum()) divided by the length of the `cmp` vector (.shape[0])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae866502",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyMetric:\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def __call__(self, y_pred: np.ndarray, y_ref: np.ndarray) -> float:\n",
    "        y_pred_max = np.argmax(y_pred, axis=1)\n",
    "        cmp = y_pred_max == y_ref\n",
    "        score = cmp.sum() / cmp.shape[0]\n",
    "\n",
    "        return score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb8cd9e7",
   "metadata": {},
   "source": [
    "We are creating a `CrossEntropyLoss` class. This is not required and can return 0 by default. However, if anyone would be interested in an `additional task`, it can be implemented based on the PyTorch documentation or the internet :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb0a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "        \n",
    "    def __call__(self, \n",
    "                 y_pred: np.ndarray, \n",
    "                 y_ref: np.ndarray\n",
    "                 ) -> Any:\n",
    "        \n",
    "        return 0.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "592772ad",
   "metadata": {},
   "source": [
    "We initialise the data generator, the metric, the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ac42ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = \n",
    "metric = AccuracyMetric() #TODO\n",
    "criterion = CrossEntropyLoss() #TODO\n",
    "tm = TimeMeasurement(\"Evaluation on KV260\", loader.batch_size * len(loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cfafb34",
   "metadata": {},
   "source": [
    "Define the `softmax` function. See how it works in the PyTorch documentation or on the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2229e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: np.ndarray, axis=1):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=axis, keepdims=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcb90dce",
   "metadata": {},
   "source": [
    "We create the NetworkDPU class. During initialisation it takes the compiled `MiniResNet_qu.xmodel` and the path to the `dpu.bit` file. The other `dpu` files must be in the same folder and must have the same name!\n",
    "\n",
    "The `input_float_to_int8` function converts data from the `float` space to `int8`.\n",
    "\n",
    "The `output_int8_to_float` function performs the reverse operation.\n",
    "\n",
    "The `process` function performs data processing. Implement it by performing the following operations:\n",
    "1. convert the input data `x` from `float` space to `int` space,\n",
    "2. write the converted data to the zero index of the input buffer `buff_in`,\n",
    "3. call the function `self.dpu.execute_async`, where you specify the input buffer as the first parameter and the output buffer as the second parameter. The function will return an index - write it to the `job_id` variable,\n",
    "4. wait for the computation thread to execute - use the `self.dpu.wait` function, where the parameter is the index `job_id`.\n",
    "5. read the first value from the `buff_out` buffer. Assign it to the `y` variable,\n",
    "6. convert the `y` variable to type `float`,\n",
    "7. execute the `softmax` function on the `y` variable and return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "364364fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkDPU:\n",
    "    \n",
    "    def __init__(self, xmodel_path: str = 'MiniResNet_qu.xmodel', dpu_path: str = 'dpu.bit'):\n",
    "        self.ov: pynq_dpu.DpuOverlay = pynq_dpu.DpuOverlay(dpu_path, download=True)\n",
    "        self.ov.load_model(xmodel_path)\n",
    "        self.dpu = self.ov.runner\n",
    "        print(self.ov.runner)\n",
    "        inputTensors = self.dpu.get_input_tensors()\n",
    "        outputTensors = self.dpu.get_output_tensors()\n",
    "        # get list of shapes\n",
    "        shapeIn = np.array([it.dims for it in inputTensors])\n",
    "        shapeOut = np.array([ot.dims for ot in outputTensors])\n",
    "        self.shapeIn = shapeIn\n",
    "        self.shapeOut = shapeOut\n",
    "        self.buff_in = [np.zeros(sh, np.int8, order='C') for sh in shapeIn]\n",
    "        self.buff_out = [np.zeros(sh, np.int8, order='C') for sh in shapeOut]\n",
    "        \n",
    "        self.input_repr = [(it.get_attr('bit_width'), it.get_attr('fix_point')) for it in inputTensors]\n",
    "        self.output_repr = [(ot.get_attr('bit_width'), ot.get_attr('fix_point')) for ot in outputTensors]\n",
    "    \n",
    "    def input_float_to_int8(self, x: np.ndarray) -> np.ndarray:\n",
    "        BIT_WIDTH, PRECISION_BITS = self.input_repr[0]\n",
    "        x = x * (2**PRECISION_BITS)\n",
    "        x = np.floor(x)\n",
    "        x = np.clip(x,-128, 127)\n",
    "        return x.astype(np.int8)\n",
    "    \n",
    "    def output_int8_to_float(self, y: np.ndarray):\n",
    "        BIT_WIDTH, PRECISION_BITS = self.output_repr[0]\n",
    "        PRECISION = 1 / 2**PRECISION_BITS\n",
    "        y = y * PRECISION\n",
    "        return y.astype(np.float32)\n",
    "    \n",
    "    def process(self, x: np.ndarray):\n",
    "        # convert the input data `x` from `float` space to `int` space,\n",
    "        x = self.input_float_to_int8(x)\n",
    "        # write the converted data to the zero index of the input buffer `buff_in`\n",
    "        self.buff_in[0] = x\n",
    "        # start DPU thread\n",
    "        # call the function `self.dpu.execute_async`, where you specify the input buffer as the first parameter and the output buffer as the second parameter. \n",
    "        # The function will return an index - write it to the `job_id` variable\n",
    "        job_id = self.dpu.execute_async(self.buff_in, self.buff_out)\n",
    "        self.dpu.wait(job_id)\n",
    "        # read the first value from the `buff_out` buffer. Assign it to the `y` variable\n",
    "        y = self.buff_out[0]\n",
    "        y = self.output_int8_to_float(y)\n",
    "        y = softmax(y)\n",
    "        return y\n",
    "    \n",
    "    def __call__(self, x: np.ndarray) -> Any:\n",
    "        return self.process(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f150c17",
   "metadata": {},
   "source": [
    "Initialise the DPU network model, providing paths to the model and the `dpu.bit` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e3fb127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vart::Runner@0x39a31f50\n"
     ]
    }
   ],
   "source": [
    "net = NetworkDPU(xmodel_path='MiniResNet_qu.xmodel', \n",
    "                 dpu_path='dpu.bit')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fb98438",
   "metadata": {},
   "source": [
    "We are creating a function to evaluate the model. If someone has implemented Cross Entropy function, the loss value will be taken into account. Otherwise it will return 0 and we will not pay attention to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61b7ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model: NetworkDPU,\n",
    "               data_loader: EvalLoader,\n",
    "               criterion: CrossEntropyLoss,\n",
    "               metric: AccuracyMetric,\n",
    "               ) -> Tuple[float, float]:\n",
    "\n",
    "    print(f\"Running on platform: {platform.platform()}, \"\n",
    "          f\"machine: {platform.machine()}, \"\n",
    "          f\"python_version: {platform.python_version()}, \"\n",
    "          f\"processor: {platform.processor()}, \"\n",
    "          f\"system: {platform.system()}, \"\n",
    "          )\n",
    "    total_loss: float = 0.0\n",
    "    total_accuracy: float = 0.0\n",
    "    samples_num: int = 0\n",
    "    \n",
    "    for i, (X, y_ref) in tqdm.tqdm(enumerate(data_loader),):\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = criterion(y_pred, y_ref)\n",
    "        \n",
    "        # calculate accuracy\n",
    "        accuracy = metric(y_pred, y_ref)\n",
    "\n",
    "        total_loss += loss * y_pred.shape[0]\n",
    "        total_accuracy += accuracy * y_pred.shape[0]\n",
    "        samples_num += y_pred.shape[0]\n",
    "\n",
    "    if samples_num == 0:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    return total_loss / samples_num, total_accuracy / samples_num\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85113b4c",
   "metadata": {},
   "source": [
    "Start the evaluation. Compare the results obtained when evaluating the floating point model.\n",
    "\n",
    "An increase in the amount of data processed per second is expected, with minimal or zero loss of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c5236e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on platform: Linux-5.4.0-1021-xilinx-zynqmp-aarch64-with-glibc2.29, machine: aarch64, python_version: 3.8.10, processor: aarch64, system: Linux, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:07, 1412.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0:0:7:0, processed 10000 frames, throughput: 1428.5714285714287 fps.\n",
      "Loss:  0.0\n",
      "Accuracy:  0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with tm:\n",
    "    loss, acc = evaluation(net, loader, criterion, metric)\n",
    "    \n",
    "print(str(tm))\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e53c6ce",
   "metadata": {},
   "source": [
    "## You have successfully completed all the tasks! Congratulations :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
